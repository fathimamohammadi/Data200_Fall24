{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a60694c",
   "metadata": {},
   "source": [
    "# Data 200: Data Systems for Data Analytics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9048bf2",
   "metadata": {},
   "source": [
    "# Name: fathima mohammadi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d999038",
   "metadata": {},
   "source": [
    "# Take Home Final Exam\n",
    "<font color='red'>**Due Date:** Dec 20, 5p (T-F 1:30p section) </font> <br>\n",
    "<font color='red' style=\"margin-left: 1.85cm; display: inline-block;\">Dec 21, 11:59a (T-F 3p section)</font>\n",
    "\n",
    "---\n",
    "\n",
    "### **Task**: Scrape data from Goodreads.com üìö\n",
    "\n",
    "---\n",
    "\n",
    "### **Objective**\n",
    "For this exam, you will scrape and analyze data from Goodreads.com. The work is split into two parts, each focusing on different aspects of the data\n",
    "1. **\"Best Books\" Analysis**: Explore Goodreads' \"Best Books\" lists for a specific year.\n",
    "2. **Author-Level Analysis**: Study the trends and patterns in the works of a specific author.\n",
    "\n",
    "---\n",
    "\n",
    "### **Instructions**\n",
    "\n",
    "#### **Task 1: Best Books**\n",
    "You are tasked with analyzing Goodreads' \"Best Books\" lists for a specific year based on the **first letter of your first name**. For example, if your first name starts with **A‚ÄìE**, you are assigned to the year **2023**; if it starts with **F‚ÄìJ**, you are assigned to **2022**, and so on:\n",
    "\n",
    "| Initials | Assigned Year | URL                                              |\n",
    "|----------|---------------|---------------------------------------------------------|\n",
    "| A‚ÄìE      | 2023          | [Best Books of 2023](https://www.goodreads.com/list/best_of_year/2023) |\n",
    "| F‚ÄìJ      | 2022          | [Best Books of 2022](https://www.goodreads.com/list/best_of_year/2022) |\n",
    "| K‚ÄìO      | 2021          | [Best Books of 2021](https://www.goodreads.com/list/best_of_year/2021) |\n",
    "| P‚ÄìT      | 2020          | [Best Books of 2020](https://www.goodreads.com/list/best_of_year/2020) |\n",
    "| U‚ÄìZ      | 2019          | [Best Books of 2019](https://www.goodreads.com/list/best_of_year/2019) |\n",
    "\n",
    "\n",
    "\n",
    "**Your Tasks**:\n",
    "1. Scrape data from the Goodreads \"Best Books of [Year]\" list:\n",
    "   - **URL**: https://www.goodreads.com/list/best_of_year/2023 (replace the year with your assigned year). You can also use the table above.\n",
    "2. Collect the following data for each book:\n",
    "   - Title\n",
    "   - Publication date (first published)\n",
    "   - Author\n",
    "   - Genre (if available, and feel free to pick the first genre listed)\n",
    "   - Average rating\n",
    "   - Number of ratings\n",
    "   - Number of pages\n",
    "   - Rank\n",
    "   - Language (if available)\n",
    "   - Number of people who are currently reading (if available)\n",
    "   - Number of people who want to read (if available)\n",
    "3. Perform the following analyses:\n",
    "   - **Genre ratings**:\n",
    "       - Compare average ratings across genres. Which 2-3 genres tends to have the highest ratings? Create a table showing average rating score, and average rank by genre.\n",
    "   - **Popularity and ratings**:\n",
    "       - Examine whether books with more ratings tend to have higher or lower average scores. Create a scatterplot showing the relationship between the number of ratings and average rating. On the x-axis, you should have **number of ratings**; on the y-axis, you should have **average rating**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Task 2: Author-Level Analysis**\n",
    "You are now tasked with analyzing books by a specific author based on the **first letter of your first name**:\n",
    "\n",
    "| Your first name initial | Author              | Author Goodreads link                               | Birthday       |\n",
    "|----------|---------------------|--------------------------------------------------------------------|----------------|\n",
    "| A‚ÄìE      | Stephen King        | [Stephen King](https://www.goodreads.com/author/list/3389)         | Sep 21, 1947   |\n",
    "| F‚ÄìJ      | George R.R. Martin  | [George R.R. Martin](https://www.goodreads.com/author/list/346732) | Sep 20, 1948   |\n",
    "| K‚ÄìO      | Ernest Hemingway    | [Ernest Hemingway](https://www.goodreads.com/author/list/1455)     | Jul 21, 1899   |\n",
    "| P‚ÄìT      | Neil Gaiman         | [Neil Gaiman](https://www.goodreads.com/author/list/1221698)       | Nov 10, 1960   |\n",
    "| U‚ÄìZ      | Nora Roberts        | [Nora Roberts](https://www.goodreads.com/author/list/625)          | Oct 10, 1950   |\n",
    "\n",
    "\n",
    "**Your Tasks**:\n",
    "1. Scrape all books by your assigned author:\n",
    "   - Use the link provided for your author.\n",
    "2. Collect the following data for each book:\n",
    "   - Title\n",
    "   - Publication date (first published)\n",
    "   - Author\n",
    "   - Genre (if available, and feel free to pick the first genre listed)\n",
    "   - Average rating\n",
    "   - Number of ratings\n",
    "   - Number of pages\n",
    "   - Rank (from the books written by the author)\n",
    "   - Language (if available)\n",
    "   - Number of people who are currently reading (if available)\n",
    "   - Number of people who want to read (if available)\n",
    "3. Perform the following analyses:\n",
    "   - **Language Distribution**:\n",
    "     - How many books has the author published in English? In other languages? Create a table showing the count of books by language.\n",
    "   - **Author's Age and Page Count**:\n",
    "     - Do authors tend to write longer books as they age? Use the author's birthday to calculate their age at the time of each book's publication. Create a line plot with **author's age** on the x-axis and **page count** on the y-axis.\n",
    "   - **Author's Age and Rating**:\n",
    "     - For English-only books, create a line plot with **author's age** on the x-axis and **average rating** on the y-axis.\n",
    "     - Repeat the analysis including books in languages other than English. Does your interpretation change?\n",
    "   - **Pages vs. Ratings**:\n",
    "     - Is there a relationship between the number of pages and a book's average rating? Create a scatterplot with **page count** on the x-axis and **average rating** on the y-axis.\n",
    "   - **Interest on a book**:\n",
    "     - Is there a relationship between the number of people who are currently reading the book and the number of people who left a rating? Create a scatterplot with **number of people who are currently reading** on the x-axis and **number of ratings** on the y-axis. Create a second scatterplot with **average rating** on the y-axis. Do books with more interest tend to receive higher ratings?\n",
    "\n",
    "---\n",
    "\n",
    "### **Submission Requirements**\n",
    "Submit your work as a single `.ipynb` file, along with a copy of it as a `.md` file. The notebook should include:\n",
    "1. **Code**:\n",
    "   - Well-documented python code using Selenium for web scraping.\n",
    "   - Proper error handling and strategies for dynamic content.\n",
    "2. **Cleaned Data**:\n",
    "   - Include the cleaned datasets from both tasks as .csv files. You can upload them in your github repo.\n",
    "3. **Analysis and Report**:\n",
    "   - Present your findings using markdown cells, tables, and visualizations you make in python.\n",
    "   - Address all questions posed for your assigned tasks.\n",
    "4. **Visualizations**:\n",
    "   - Include relevant charts (e.g., bar charts, line plots, scatterplots) to support your conclusions.\n",
    "\n",
    "---\n",
    "\n",
    "### **Rubric**\n",
    "\n",
    "| Item                        | Weight |\n",
    "|-----------------------------|--------|\n",
    "| Code accuracy               | 25%    |\n",
    "| Code clarity and annotation | 25%    |\n",
    "| Exploratory data analysis   | 25%    |\n",
    "| Discussion of findings      | 25%    |\n",
    "\n",
    "---\n",
    "\n",
    "### **Tips**\n",
    "- Make sure to insert time.sleep() right after you request driver to go to a link (before requesting elements). Make sure to wait at least 0.7 second, or even slightly higher if you run into issues.\n",
    "- Try-except blocks will be your friend because xpath positions on a page may differ depending on the book and content availability.\n",
    "\n",
    "---\n",
    "\n",
    "### **Resources**\n",
    "- Course notes on Github\n",
    "- Selenium documentation: https://www.selenium.dev/documentation/\n",
    "- Pandas documentation: https://pandas.pydata.org/docs/\n",
    "- Matplotlib documentation: https://matplotlib.org/stable/contents.html\n",
    "\n",
    "Good luck! üèÅ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a599640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "\n",
    "url = 'https://www.goodreads.com/list/best_of_year/2022'\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "response = requests.get(url,headers=headers)\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e32ac026-58aa-420a-ae9d-dd2075f65ec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /opt/anaconda3/lib/python3.12/site-packages (4.27.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/anaconda3/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Requirement already satisfied: trio~=0.17 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /opt/anaconda3/lib/python3.12/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/anaconda3/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /opt/anaconda3/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4392973d-0a68-4418-a5ca-d6ea7b3e0395",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: disconnected: Unable to receive message from renderer\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=131.0.6778.205)\nStacktrace:\n0   chromedriver                        0x000000010154f184 cxxbridge1$str$ptr + 3626716\n1   chromedriver                        0x00000001015479d4 cxxbridge1$str$ptr + 3596076\n2   chromedriver                        0x0000000100fb4968 cxxbridge1$string$len + 89228\n3   chromedriver                        0x0000000100f9fc90 cxxbridge1$string$len + 4020\n4   chromedriver                        0x0000000100f9fa00 cxxbridge1$string$len + 3364\n5   chromedriver                        0x0000000100f9ea9c core::str::slice_error_fail::ha0e52dbcb60e6bae + 64284\n6   chromedriver                        0x0000000100fbf7c4 cxxbridge1$string$len + 133864\n7   chromedriver                        0x0000000101032780 cxxbridge1$string$len + 604836\n8   chromedriver                        0x0000000100fed568 cxxbridge1$string$len + 321676\n9   chromedriver                        0x0000000100fee1b8 cxxbridge1$string$len + 324828\n10  chromedriver                        0x000000010151a9ac cxxbridge1$str$ptr + 3411716\n11  chromedriver                        0x000000010151dccc cxxbridge1$str$ptr + 3424804\n12  chromedriver                        0x000000010150186c cxxbridge1$str$ptr + 3308996\n13  chromedriver                        0x000000010151e58c cxxbridge1$str$ptr + 3427044\n14  chromedriver                        0x00000001014f309c cxxbridge1$str$ptr + 3249652\n15  chromedriver                        0x00000001015384b8 cxxbridge1$str$ptr + 3533328\n16  chromedriver                        0x0000000101538634 cxxbridge1$str$ptr + 3533708\n17  chromedriver                        0x0000000101547648 cxxbridge1$str$ptr + 3595168\n18  libsystem_pthread.dylib             0x000000019ea2c2e4 _pthread_start + 136\n19  libsystem_pthread.dylib             0x000000019ea270fc thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome()\n\u001b[1;32m     11\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.goodreads.com/list/best_of_year/2022\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[1;32m     14\u001b[0m titles \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m authors \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:393\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: url})\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:384\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    382\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[1;32m    385\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py:232\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    230\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: disconnected: Unable to receive message from renderer\n  (failed to check if window was closed: disconnected: not connected to DevTools)\n  (Session info: chrome=131.0.6778.205)\nStacktrace:\n0   chromedriver                        0x000000010154f184 cxxbridge1$str$ptr + 3626716\n1   chromedriver                        0x00000001015479d4 cxxbridge1$str$ptr + 3596076\n2   chromedriver                        0x0000000100fb4968 cxxbridge1$string$len + 89228\n3   chromedriver                        0x0000000100f9fc90 cxxbridge1$string$len + 4020\n4   chromedriver                        0x0000000100f9fa00 cxxbridge1$string$len + 3364\n5   chromedriver                        0x0000000100f9ea9c core::str::slice_error_fail::ha0e52dbcb60e6bae + 64284\n6   chromedriver                        0x0000000100fbf7c4 cxxbridge1$string$len + 133864\n7   chromedriver                        0x0000000101032780 cxxbridge1$string$len + 604836\n8   chromedriver                        0x0000000100fed568 cxxbridge1$string$len + 321676\n9   chromedriver                        0x0000000100fee1b8 cxxbridge1$string$len + 324828\n10  chromedriver                        0x000000010151a9ac cxxbridge1$str$ptr + 3411716\n11  chromedriver                        0x000000010151dccc cxxbridge1$str$ptr + 3424804\n12  chromedriver                        0x000000010150186c cxxbridge1$str$ptr + 3308996\n13  chromedriver                        0x000000010151e58c cxxbridge1$str$ptr + 3427044\n14  chromedriver                        0x00000001014f309c cxxbridge1$str$ptr + 3249652\n15  chromedriver                        0x00000001015384b8 cxxbridge1$str$ptr + 3533328\n16  chromedriver                        0x0000000101538634 cxxbridge1$str$ptr + 3533708\n17  chromedriver                        0x0000000101547648 cxxbridge1$str$ptr + 3595168\n18  libsystem_pthread.dylib             0x000000019ea2c2e4 _pthread_start + 136\n19  libsystem_pthread.dylib             0x000000019ea270fc thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the Chrome driver service)  # Update with the correct path to your chromedriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = 'https://www.goodreads.com/list/best_of_year/2022'\n",
    "driver.get(url)\n",
    "\n",
    "titles = []\n",
    "authors = []\n",
    "ratings = []\n",
    "\n",
    "for book in book_rows:\n",
    "    try:\n",
    "        book_rows = driver.find_elements('xpath', \"//*[@id='bodycontainer']/div[3]/div[1]/div[2]/div[2]/table/tbody/tr[1]/td[2]/a/span\")\n",
    "    except:\n",
    "        title = 'N/A'\n",
    "    titles.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b1de70d-c0d0-4f5e-a3d1-e0f9a60744cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html class=\"desktop withSiteHeaderTopFullImage\n",
      " picture es5array es5date es5function es5object strictmode es5string json es5syntax es5undefined es5 no-touchevents cssanimations flexbox flexwrap csstransforms localstorage\" style=\"\"><head>\n",
      "  <title>Best Books of 2022 (1515 books)</title>\n",
      "\n",
      "<meta content=\"1,515 books based on 1829 votes: Book Lovers by Emily Henry, Lessons in Chemistry by Bonnie Garmus, I'm Glad My Mom Died by Jennette McCurdy, Reminders o...\" name=\"description\">\n",
      "<meta content=\"telephone=no\" name=\"format-detection\">\n",
      "<link href=\"https://www.goodreads.com/list/best_of_year/2022?id=171064.Best_Books_of_2022\" rel=\"canonical\">\n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "  <!-- * Copied from https://info.analytics.a2z.com/#/docs/data_collection/csa/onboard */ -->\n",
      "<script src=\"https://rules.quantcount.com/rules-p-0dUe_kJAjvkoY.js\" async=\"\"></script><script async=\"\" src=\"https://sb.scorecardresearch.com/beacon.js\"></script><script src=\"https://secure.quantserve.com/aquant.js?a=p-0dUe_kJAjvkoY\" async=\"\" type=\"text/javascript\"></script><script async=\"\" src=\"//c.amazon-adsystem.com/aax2/apstag.js\"></script><script async=\"\" type=\"text/javascript\" src=\"https://securepubads.g.doubleclick.net/tag/js/gpt.js\"></script><script id=\"twitter-wjs\" src=\"https://platform.twitter.com/widgets.js\"></script><script>\n",
      "  //<![CDATA[\n",
      "    !function(){function n(n,t){var r=i(n);return t&&(r=r(\"instance\",t)),r}var r=[],c=0,i=function(t){return function(){var n=c++;return r.push([t,[].slice.call(arguments,0),n,{time:Date.now()}]),i(n)}};n._s=r,this.csa=n}();\n",
      "    \n",
      "    if (window.csa) {\n",
      "      window.csa(\"Config\", {\n",
      "        \"Application\": \"GoodreadsMonolith\",\n",
      "        \"Events.SushiEndpoint\": \"https://unagi.amazon.com/1/events/com.amazon.csm.csa.prod\",\n",
      "        \"Events.Namespace\": \"csa\",\n",
      "        \"CacheDetection.RequestID\": \"W1QT0KHW1XFBBSHZDKVB\",\n",
      "        \"ObfuscatedMarketplaceId\": \"A1PQBFHBHS6YH1\"\n",
      "      });\n",
      "    \n",
      "      window.csa(\"Events\")(\"setEntity\", {\n",
      "        session: { id: \"005-5308660-9801391\" },\n",
      "        page: {requestId: \"W1Q\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = 'https://www.goodreads.com/list/best_of_year/2022'\n",
    "driver.get(url)\n",
    "time.sleep(5) # give more time for the data to be able to load\n",
    "\n",
    "html_source = driver.page_source\n",
    "print(html_source[:2000])\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf075780-3d7d-4e67-b767-45a26bb9fd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomeMy Books\n",
      "Browse ‚ñæ\n",
      "Community ‚ñæ\n",
      "Sign InJoin\n",
      "\n",
      "Listopia\n",
      "\n",
      "Best Books of 2022\n",
      "The best books published during 2022.\n",
      "\n",
      "For 2022\n",
      "2022 books most frequently added to shelves\n",
      "2022 lists\n",
      "2022 shelf\n",
      "Graphic Novels of 2022\n",
      "Picture Books of 2021\n",
      "YA Novels of 2022\n",
      "\n",
      "By year:\n",
      "1889\n",
      "1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "\n",
      ", , , , , , , , ,\n",
      ", , , , , , , , , ,\n",
      ", , , , , , , , ,\n",
      ", , , , , , , , ,\n",
      ", , , , , , , , ,\n",
      ", , , ,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FEATURED NEWS & INTERVIEWS\n",
      "\n",
      "\n",
      "\n",
      "Discover & read more\n",
      "Sign up to get better recommendations with a free account.\n",
      "Continue with Amazon\n",
      "Sign up with email\n",
      "Already a member? Sign in\n",
      "By clicking ‚ÄúSign up‚Äù I agree to the Goodreads Terms of Service and confirm that I am at least 13 years old. Read our Privacy Policy\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = 'https://www.goodreads.com/list/best_of_year/2022'\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "html_body = driver.find_element('tag name', 'body').text\n",
    "print(html_body[:3000])\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2437cd6-4165-4d5f-b6be-ecd67e0e42c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomeMy Books\n",
      "Browse ‚ñæ\n",
      "Community ‚ñæ\n",
      "Sign InJoin\n",
      "\n",
      "Listopia\n",
      "\n",
      "Best Books of 2022\n",
      "The best books published during 2022.\n",
      "\n",
      "For 2022\n",
      "2022 books most frequently added to shelves\n",
      "2022 lists\n",
      "2022 shelf\n",
      "Graphic Novels of 2022\n",
      "Picture Books of 2021\n",
      "YA Novels of 2022\n",
      "\n",
      "By year:\n",
      "1889\n",
      "1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "\n",
      ", , , , , , , , ,\n",
      ", , , , , , , , , ,\n",
      ", , , , , , , , ,\n",
      ", , , , , , , , ,\n",
      ", , , , , , , , ,\n",
      ", , , ,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FEATURED NEWS & INTERVIEWS\n",
      "\n",
      "\n",
      "\n",
      "Discover & read more\n",
      "Sign up to get better recommendations with a free account.\n",
      "Continue with Amazon\n",
      "Sign up with email\n",
      "Already a member? Sign in\n",
      "By clicking ‚ÄúSign up‚Äù I agree to the Goodreads Terms of Service and confirm that I am at least 13 years old. Read our Privacy Policy\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = \"https://www.goodreads.com/list/best_of_year/2022\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "for _ in range(10):\n",
    "    driver.find_element(By.TAG_NAME,'body').send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(2)\n",
    "\n",
    "html_body = driver.find_element(By.TAG_NAME,'body').text\n",
    "print(html_body[:3000]) \n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00c49a0d-a0c3-4c24-ba58-8554c8f90f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking page source...\n",
      "<html class=\"desktop withSiteHeaderTopFullImage\n",
      " picture es5array es5date es5function es5object strictmode es5string json es5syntax es5undefined es5 no-touchevents cssanimations flexbox flexwrap csstransforms localstorage\" style=\"\"><head>\n",
      "  <title>Best Books of 2022 (1515 books)</title>\n",
      "\n",
      "<meta content=\"1,515 books based on 1829 votes: Book Lovers by Emily Henry, Lessons in Chemistry by Bonnie Garmus, I'm Glad My Mom Died by Jennette McCurdy, Reminders o...\" name=\"description\">\n",
      "<meta content=\"telephone=no\" name=\"format-detection\">\n",
      "<link href=\"https://www.goodreads.com/list/best_of_year/2022?id=171064.Best_Books_of_2022\" rel=\"canonical\">\n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "  <!-- * Copied from https://info.analytics.a2z.com/#/docs/data_collection/csa/onboard */ -->\n",
      "<script src=\"https://rules.quantcount.com/rules-p-0dUe_kJAjvkoY.js\" async=\"\"></script><script async=\"\" src=\"https://sb.scorecardresearch.com/beacon.js\"></script><script src=\"https://secure.quantserve.com/aquant.js?a=p-0dUe_kJAjvkoY\" async=\"\" type=\"text/javascript\"></script><script async=\"\" src=\"//c.amazon-adsystem.com/aax2/apstag.js\"></script><script async=\"\" type=\"text/javascript\" src=\"https://securepubads.g.doubleclick.net/tag/js/gpt.js\"></script><script id=\"twitter-wjs\" src=\"https://platform.twitter.com/widgets.js\"></script><script>\n",
      "  //<![CDATA[\n",
      "    !function(){function n(n,t){var r=i(n);return t&&(r=r(\"instance\",t)),r}var r=[],c=0,i=function(t){return function(){var n=c++;return r.push([t,[].slice.call(arguments,0),n,{time:Date.now()}]),i(n)}};n._s=r,this.csa=n}();\n",
      "    \n",
      "    if (window.csa) {\n",
      "      window.csa(\"Config\", {\n",
      "        \"Application\": \"GoodreadsMonolith\",\n",
      "        \"Events.SushiEndpoint\": \"https://unagi.amazon.com/1/events/com.amazon.csm.csa.prod\",\n",
      "        \"Events.Namespace\": \"csa\",\n",
      "        \"CacheDetection.RequestID\": \"NG08P0X03KNGG8TTADG0\",\n",
      "        \"ObfuscatedMarketplaceId\": \"A1PQBFHBHS6YH1\"\n",
      "      });\n",
      "    \n",
      "      window.csa(\"Events\")(\"setEntity\", {\n",
      "        session: { id: \"174-2969711-1988014\" },\n",
      "        page: {requestId: \"NG0\n",
      "Number of books found: 0\n",
      "The Data Is Saved Successfully To 'goodreads_fixed_books.csv'.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = 'https://www.goodreads.com/list/best_of_year/2022'\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "for _ in range(10):\n",
    "    driver.find_element(By.TAG_NAME,'body').send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(2)\n",
    "\n",
    "print('Checking page source...')\n",
    "print(driver.page_source[:2000])\n",
    "\n",
    "titles = []\n",
    "authors = []\n",
    "ratings = []\n",
    "\n",
    "try:\n",
    "    \n",
    "    book_rows = driver.find_elements(By.XPATH, \"//tr[contains(@class, 'bookalike')]\")\n",
    "    print(f\"Number of books found: {len(book_rows)}\")\n",
    "\n",
    "    for book in book_rows:\n",
    "        try:\n",
    "            title = book.find_element(By.XPATH, \".//a[contains(@class, 'bookTitle')]\").text.strip()\n",
    "        except:\n",
    "            title = \"N/A\"\n",
    "        titles.append(title)\n",
    "\n",
    "        try:\n",
    "            author = book.find_element(By.XPATH, \".//a[contains(@class, 'authorName')]\").text.strip()\n",
    "        except:\n",
    "            author = \"N/A\"\n",
    "        authors.append(author)\n",
    "\n",
    "        try:\n",
    "            rating = book.find_element(By.XPATH, \".//span[contains(@class, 'minirating')]\").text.split(\"‚Äî\")[0].strip()\n",
    "        except:\n",
    "            rating = \"N/A\"\n",
    "        ratings.append(rating)\n",
    "\n",
    "except Exception as e:\n",
    "    print('There Was An Error During Extraction:', e)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Title': titles,\n",
    "    'Author': authors,\n",
    "    'Average Rating': ratings\n",
    "})\n",
    "\n",
    "df.to_csv('goodreads_fixed_books.csv', index=False)\n",
    "print(\"The Data Is Saved Successfully To 'goodreads_fixed_books.csv'.\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b39ad1-a7d8-4252-a447-ef4915cb1349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Data Is Saved Successfully To 'goodreads_best_books_2022.csv'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "url = \"https://www.goodreads.com/list/best_of_year/2022\"\n",
    "\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "titles = []\n",
    "authors = []\n",
    "ratings = []\n",
    "\n",
    "book_rows = driver.find_elements(By.CSS_SELECTOR, \"table.tableList tr\")\n",
    "\n",
    "for row in book_rows:\n",
    "    try:\n",
    "        # Title\n",
    "        title = row.find_element(By.CSS_SELECTOR, \"a.bookTitle span\").text.strip()\n",
    "        titles.append(title)\n",
    "    except:\n",
    "        titles.append(\"N/A\")\n",
    "\n",
    "    try:\n",
    "        # Author\n",
    "        author = row.find_element(By.CSS_SELECTOR, \"span[itemprop='author']\").text.strip()\n",
    "        authors.append(author)\n",
    "    except:\n",
    "        authors.append(\"N/A\")\n",
    "\n",
    "    try:\n",
    "        # Ratings\n",
    "        rating = row.find_element(By.CSS_SELECTOR, \"span.minirating\").text.split()[0]\n",
    "        ratings.append(float(rating))\n",
    "    except:\n",
    "        ratings.append(0.0)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Title': titles,\n",
    "    'Author': authors,\n",
    "    'Average Rating': ratings\n",
    "})\n",
    "\n",
    "df.to_csv('goodreads_best_books_2022.csv',index = False)\n",
    "print(\"The Data Is Saved Successfully To 'goodreads_best_books_2022.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec17580f-2450-4d41-993f-27bd7290ef43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully to 'goodreads_best_books_2022_cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# URL of Goodreads Best Books of 2020\n",
    "url = \"https://www.goodreads.com/list/best_of_year/2022\"\n",
    "\n",
    "# Load the webpage\n",
    "driver.get(url)\n",
    "time.sleep(3)  # Allow time for the page to fully load\n",
    "\n",
    "# Lists to store the scraped data\n",
    "titles = []\n",
    "authors = []\n",
    "ratings = []\n",
    "\n",
    "# Locate book rows\n",
    "book_rows = driver.find_elements(By.CSS_SELECTOR, \"table.tableList tr\")\n",
    "\n",
    "# Extract data for each book\n",
    "for row in book_rows:\n",
    "    try:\n",
    "        # Title\n",
    "        title = row.find_element(By.CSS_SELECTOR, \"a.bookTitle span\").text.strip()\n",
    "        if not title:\n",
    "            continue  # Skip rows with missing titles\n",
    "        titles.append(title)\n",
    "    except:\n",
    "        continue  # Skip problematic rows\n",
    "\n",
    "    try:\n",
    "        # Author\n",
    "        author = row.find_element(By.CSS_SELECTOR, \"a.authorName span\").text.strip()\n",
    "        authors.append(author)\n",
    "    except:\n",
    "        authors.append(\"N/A\")  # If author is missing\n",
    "\n",
    "    try:\n",
    "        # Average Rating\n",
    "        rating_text = row.find_element(By.CSS_SELECTOR, \"span.minirating\").text.strip()\n",
    "        rating = float(rating_text.split()[0])  # Extract the numerical part\n",
    "        ratings.append(rating)\n",
    "    except:\n",
    "        ratings.append(0.0)  # Default to 0 if rating is missing\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Author\": authors,\n",
    "    \"Average Rating\": ratings\n",
    "})\n",
    "\n",
    "# Remove rows with empty or invalid data\n",
    "df = df[df['Title'] != \"\"]\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"goodreads_best_books_2022_cleaned.csv\", index=False)\n",
    "print(\"Data saved successfully to 'goodreads_best_books_2022_cleaned.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef610148-3c7e-434f-ac41-f5d0a07a6cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted genre: Not Found for URL: /book/show/44778083-the-house-in-the-cerulean-sea\n",
      "Extracted genre: Not Found for URL: /book/show/44778083-house-of-earth-and-blood\n",
      "Genres saved to 'book_genres.csv'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Initialize Selenium WebDriver\n",
    "driver = webdriver.Chrome()  # Make sure you have ChromeDriver installed\n",
    "base_url = \"https://www.goodreads.com\"\n",
    "\n",
    "# Example list of book URLs (replace with your own list of extracted URLs)\n",
    "book_urls = [\n",
    "    \"/book/show/44778083-the-house-in-the-cerulean-sea\",\n",
    "    \"/book/show/44778083-house-of-earth-and-blood\"\n",
    "]\n",
    "\n",
    "# List to store data\n",
    "books_data = []\n",
    "\n",
    "# Loop through each book page\n",
    "for url in book_urls:\n",
    "    driver.get(base_url + url)\n",
    "    time.sleep(2)  # Wait for the page to load\n",
    "    \n",
    "    try:\n",
    "        # Extract the first genre listed on the page\n",
    "        genre = driver.find_element(By.CLASS_NAME, \"bookPageGenreLink\").text\n",
    "    except:\n",
    "        genre = \"Not Found\"  # Handle missing genres\n",
    "    \n",
    "    books_data.append({\"URL\": url, \"Genre\": genre})\n",
    "    print(f\"Extracted genre: {genre} for URL: {url}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(books_data)\n",
    "df.to_csv(\"book_genres.csv\", index=False)\n",
    "print(\"Genres saved to 'book_genres.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eb927ba-0598-4514-9d3b-77170cfe7093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted genre: Romance for URL: /book/show/44778083-the-house-in-the-cerulean-sea\n",
      "Error: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=131.0.6778.205)\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000102bf3184 cxxbridge1$str$ptr + 3626716\n",
      "1   chromedriver                        0x0000000102beb9d4 cxxbridge1$str$ptr + 3596076\n",
      "2   chromedriver                        0x0000000102658968 cxxbridge1$string$len + 89228\n",
      "3   chromedriver                        0x0000000102633e44 core::str::slice_error_fail::ha0e52dbcb60e6bae + 3780\n",
      "4   chromedriver                        0x00000001026c2d48 cxxbridge1$string$len + 524396\n",
      "5   chromedriver                        0x00000001026d5c24 cxxbridge1$string$len + 601928\n",
      "6   chromedriver                        0x0000000102691568 cxxbridge1$string$len + 321676\n",
      "7   chromedriver                        0x00000001026921b8 cxxbridge1$string$len + 324828\n",
      "8   chromedriver                        0x0000000102bbe9ac cxxbridge1$str$ptr + 3411716\n",
      "9   chromedriver                        0x0000000102bc1ccc cxxbridge1$str$ptr + 3424804\n",
      "10  chromedriver                        0x0000000102ba586c cxxbridge1$str$ptr + 3308996\n",
      "11  chromedriver                        0x0000000102bc258c cxxbridge1$str$ptr + 3427044\n",
      "12  chromedriver                        0x0000000102b9709c cxxbridge1$str$ptr + 3249652\n",
      "13  chromedriver                        0x0000000102bdc4b8 cxxbridge1$str$ptr + 3533328\n",
      "14  chromedriver                        0x0000000102bdc634 cxxbridge1$str$ptr + 3533708\n",
      "15  chromedriver                        0x0000000102beb648 cxxbridge1$str$ptr + 3595168\n",
      "16  libsystem_pthread.dylib             0x000000019ea2c2e4 _pthread_start + 136\n",
      "17  libsystem_pthread.dylib             0x000000019ea270fc thread_start + 8\n",
      "\n",
      "Extracted genre: Not Found for URL: /book/show/44778083-house-of-earth-and-blood\n",
      "Genres saved to 'book_genres.csv'\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Initialize Selenium WebDriver\n",
    "driver = webdriver.Chrome()  # Make sure you have ChromeDriver installed\n",
    "base_url = \"https://www.goodreads.com\"\n",
    "\n",
    "# Example list of book URLs\n",
    "book_urls = [\n",
    "    \"/book/show/44778083-the-house-in-the-cerulean-sea\",\n",
    "    \"/book/show/44778083-house-of-earth-and-blood\"\n",
    "]\n",
    "\n",
    "# List to store extracted data\n",
    "books_data = []\n",
    "\n",
    "# Loop through each book page\n",
    "for url in book_urls:\n",
    "    driver.get(base_url + url)\n",
    "    time.sleep(3)  # Allow the page to fully load\n",
    "    \n",
    "    try:\n",
    "        # Locate genre links using the updated class\n",
    "        genre_elements = driver.find_elements(By.CSS_SELECTOR, \"a.Button.Button--tag.Button--medium span.Button__labelItem\")\n",
    "        genres = [element.text for element in genre_elements if element.text.strip()]\n",
    "        \n",
    "        # Extract the first genre or assign 'Not Found'\n",
    "        first_genre = genres[0] if genres else \"Not Found\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        first_genre = \"Not Found\"\n",
    "    \n",
    "    books_data.append({\"URL\": url, \"Genre\": first_genre})\n",
    "    print(f\"Extracted genre: {first_genre} for URL: {url}\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n",
    "\n",
    "#save the results\n",
    "df = pd.DataFrame(books_data)\n",
    "df.to_csv(\"book_genres.csv\", index=False)\n",
    "print(\"Genres saved to 'book_genres.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a06fc854-7df8-4a89-b416-d2ba83a52cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for book URLs...\n",
      "Saved book URLs to 'book_urls.csv'.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Initialize Selenium WebDriver\n",
    "driver = webdriver.Chrome()  \n",
    "base_url = \"https://www.goodreads.com/search?q=\"\n",
    "\n",
    "# Load the CSV with titles and authors\n",
    "input_file = \"goodreads_best_books_2022_cleaned.csv\"  # Replace with your CSV file name\n",
    "output_file = \"book_urls.csv\"\n",
    "\n",
    "# Read the book titles and authors\n",
    "books_df = pd.read_csv(input_file)\n",
    "book_urls = []\n",
    "\n",
    "try:\n",
    "    print(\"Searching for book URLs...\")\n",
    "    for index, row in books_df.iterrows():\n",
    "        title = row['Title']  # Make sure 'Title' matches the column name in your CSV\n",
    "        search_url = base_url + title.replace(\" \", \"+\")\n",
    "        \n",
    "        driver.get(search_url)  # Visit Goodreads search page\n",
    "        time.sleep(2)  # Wait for the page to load\n",
    "\n",
    "        try:\n",
    "            # Wait for search results to load\n",
    "            first_result = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"a.bookTitle\"))\n",
    "            )\n",
    "\n",
    "            # Get the URL of the first search result\n",
    "            book_url = first_result.get_attribute(\"href\")\n",
    "            print(f\"Found URL for '{title}': {book_url}\")\n",
    "        except:\n",
    "            book_url = \"Not Found\"\n",
    "            print(f\"URL not found for '{title}'\")\n",
    "\n",
    "        # Append the result to the list\n",
    "        book_urls.append({'Title': title,'URL': book_url})\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "#save the results\n",
    "output_df = pd.DataFrame(book_urls)\n",
    "output_df.to_csv(output_file, index=False)\n",
    "print(f\"Saved book URLs to '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f39344c3-7eef-46c0-a1fb-305b16408653",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Initialize Selenium WebDriver\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome()  \n\u001b[1;32m     11\u001b[0m base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.goodreads.com/search?q=\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Load input and output files\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[1;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     46\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mDesiredCapabilities\u001b[38;5;241m.\u001b[39mCHROME[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     47\u001b[0m     vendor_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoog\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     48\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m     49\u001b[0m     service\u001b[38;5;241m=\u001b[39mservice,\n\u001b[1;32m     50\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[1;32m     51\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py:66\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     57\u001b[0m executor \u001b[38;5;241m=\u001b[39m ChromiumRemoteConnection(\n\u001b[1;32m     58\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[1;32m     59\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mbrowser_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[1;32m     63\u001b[0m )\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(command_executor\u001b[38;5;241m=\u001b[39mexecutor, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:241\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, command_executor, keep_alive, file_detector, options, locator_converter, web_element_cls, client_config)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authenticator_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_client()\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_session(capabilities)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fedcm \u001b[38;5;241m=\u001b[39m FedCM(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_websocket_connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:329\u001b[0m, in \u001b[0;36mWebDriver.start_session\u001b[0;34m(self, capabilities)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new session with the desired capabilities.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m:Args:\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m - capabilities - a capabilities dict to start the session with.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    328\u001b[0m caps \u001b[38;5;241m=\u001b[39m _create_caps(capabilities)\n\u001b[0;32m--> 329\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mNEW_SESSION, caps)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcaps \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:382\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    380\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 382\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/remote_connection.py:404\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    402\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[1;32m    403\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[0;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(command_info[\u001b[38;5;241m0\u001b[39m], url, body\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/remote_connection.py:428\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    425\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 428\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39mrequest(method, url, body\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39mtimeout)\n\u001b[1;32m    429\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/_request_methods.py:144\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m    137\u001b[0m         method,\n\u001b[1;32m    138\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[1;32m    145\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[1;32m    146\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/_request_methods.py:279\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    275\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[1;32m    277\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import os\n",
    "\n",
    "# Initialize Selenium WebDriver\n",
    "driver = webdriver.Chrome()  \n",
    "base_url = \"https://www.goodreads.com/search?q=\"\n",
    "\n",
    "# Load input and output files\n",
    "input_file = \"goodreads_best_books_2022_cleaned.csv\"  # Replace with your CSV file name\n",
    "output_file = \"book_urls.csv\"\n",
    "\n",
    "# Load the book list\n",
    "books_df = pd.read_csv(input_file)\n",
    "\n",
    "# Try to load existing URLs into a dictionary\n",
    "if os.path.exists(output_file):\n",
    "    existing_urls = pd.read_csv(output_file).set_index('Title')['URL'].to_dict()\n",
    "else:\n",
    "    existing_urls = {}\n",
    "\n",
    "book_urls = []\n",
    "\n",
    "try:\n",
    "    print(\"Searching for book URLs...\")\n",
    "    for index, row in books_df.iterrows():\n",
    "        title = row['Title']\n",
    "        \n",
    "        # Check if the URL already exists in the dictionary\n",
    "        if title in existing_urls:\n",
    "            print(f\"Using cached URL for '{title}'\")\n",
    "            book_url = existing_urls[title]\n",
    "        else:\n",
    "            search_url = base_url + title.replace(\" \", \"+\")\n",
    "            driver.get(search_url)\n",
    "            time.sleep(2)  # Allow page to load\n",
    "\n",
    "            try:\n",
    "                # Wait for search results to load\n",
    "                first_result = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"a.bookTitle\"))\n",
    "                )\n",
    "                book_url = first_result.get_attribute(\"href\")\n",
    "                print(f\"Found URL for '{title}': {book_url}\")\n",
    "            except Exception as e:\n",
    "                book_url = \"Not Found\"\n",
    "                print(f\"URL not found for '{title}': {e}\")\n",
    "\n",
    "            # Update the dictionary with the new URL\n",
    "            existing_urls[title] = book_url\n",
    "\n",
    "        # Append the result to the list\n",
    "        book_urls.append({'Title': title, 'URL': book_url})\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "# Save the results to the output CSV file\n",
    "output_df = pd.DataFrame(book_urls)\n",
    "output_df.to_csv(output_file, index=False)\n",
    "print(f\"Saved book URLs to '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdb05ed-4164-4a1e-87b4-f399124b3147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Load URLs from the saved file\n",
    "input_file = \"book_urls.csv\"\n",
    "output_file = \"goodreads_book_data.csv\"\n",
    "\n",
    "book_data = []\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "try:\n",
    "    urls_df = pd.read_csv(input_file)\n",
    "\n",
    "    for index, row in urls_df.iterrows():\n",
    "        book_title = row['Title']\n",
    "        book_url = row['URL']\n",
    "        print(f\"Extracting data from {book_url}\")\n",
    "\n",
    "        driver.get(book_url)\n",
    "        time.sleep(2)  # Allow page to load\n",
    "\n",
    "        try:\n",
    "            # Extract Title\n",
    "            title = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"h1[data-testid='bookTitle']\"))\n",
    "            ).text\n",
    "        except:\n",
    "            title = \"Not Found\"\n",
    "\n",
    "        try:\n",
    "            # Extract Author\n",
    "            author = driver.find_element(By.CSS_SELECTOR, \"span[data-testid='authorName']\").text\n",
    "        except:\n",
    "            author = \"Not Found\"\n",
    "\n",
    "        try:\n",
    "            # Extract Average Rating\n",
    "            avg_rating = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='averageRating']\").text\n",
    "        except:\n",
    "            avg_rating = \"Not Found\"\n",
    "\n",
    "        book_data.append({\n",
    "            \"Title\": title,\n",
    "            \"Author\": author,\n",
    "            \"Average Rating\": avg_rating,\n",
    "            \"URL\": book_url\n",
    "        })\n",
    "        print(f\"Extracted: {title}, {author}, {avg_rating}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "# Save to a new CSV file\n",
    "output_df = pd.DataFrame(book_data)\n",
    "output_df.to_csv(output_file, index=False)\n",
    "print(f\"Saved book data to '{output_file}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a86e1d-5296-49a3-b375-cfa3ceab52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Initialize Selenium WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "url = \"https://www.goodreads.com/book/show/45047384-the-house-in-the-cerulean-sea?from_search=true&from_srp=true&qid=fb2xFor0tp&rank=1\"\n",
    "\n",
    "try:\n",
    "    print(\"Extracting data from:\", url)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the title to load\n",
    "    try:\n",
    "        title = WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"h1[data-testid='bookTitle']\"))\n",
    "        ).text\n",
    "    except TimeoutException:\n",
    "        title = \"Not Found\"\n",
    "    # Extract the author\n",
    "    try:\n",
    "        author = WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"span.ContributorLink__name\"))\n",
    "        ).text\n",
    "    except TimeoutException:\n",
    "        author = \"Not Found\"\n",
    "\n",
    "    # Extract average rating\n",
    "    try:\n",
    "        avg_rating = WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"div.RatingStatistics__rating\"))\n",
    "        ).text\n",
    "    except TimeoutException:\n",
    "        avg_rating = \"Not Found\"\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Title:\", title)\n",
    "    print(\"Author:\", author)\n",
    "    print(\"Average Rating:\", avg_rating)\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ecb0a7-ea36-4215-b9c2-8de4ad86550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Input and Output File Names\n",
    "input_file = \"book_urls.csv\"  # Your CSV with book URLs\n",
    "output_file = \"goodreads_book_data.csv\"\n",
    "\n",
    "# Initialize Selenium WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Read the CSV File with URLs\n",
    "books_df = pd.read_csv(input_file)\n",
    "\n",
    "# Prepare a List to Store the Results\n",
    "extracted_data = []\n",
    "\n",
    "try:\n",
    "    print(\"Extracting data for all book URLs...\")\n",
    "    for index, row in books_df.iterrows():\n",
    "        url = row['URL']\n",
    "        print(f\"Extracting data from: {url}\")\n",
    "        \n",
    "        driver.get(url)\n",
    "        \n",
    "        # Extract Title\n",
    "        try:\n",
    "            title = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"h1[data-testid='bookTitle']\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            title = \"Not Found\"\n",
    "        \n",
    "        # Extract Author\n",
    "        try:\n",
    "            author = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"span.ContributorLink__name\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            author = \"Not Found\"\n",
    "        \n",
    "        # Extract Average Rating\n",
    "        try:\n",
    "            avg_rating = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"div.RatingStatistics__rating\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            avg_rating = \"Not Found\"\n",
    "        \n",
    "        # Store the Extracted Data\n",
    "        extracted_data.append({\n",
    "            \"URL\": url,\n",
    "            \"Title\": title,\n",
    "            \"Author\": author,\n",
    "            \"Average Rating\": avg_rating\n",
    "        })\n",
    "\n",
    "        print(f\"Extracted: {title}, {author}, {avg_rating}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "# Save the Data to a CSV File\n",
    "output_df = pd.DataFrame(extracted_data)\n",
    "output_df.to_csv(output_file, index=False)\n",
    "print(f\"Saved extracted data to '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb7420c-f657-4bc9-8aef-e34a4fbcb4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Input and Output File Names\n",
    "input_file = \"book_urls.csv\"  # Your CSV with book URLs\n",
    "output_file = \"goodreads_enriched_data.csv\"\n",
    "\n",
    "# Initialize Selenium WebDriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Read the CSV File with URLs\n",
    "books_df = pd.read_csv(input_file)\n",
    "\n",
    "# Prepare a List to Store the Results\n",
    "extracted_data = []\n",
    "\n",
    "try:\n",
    "    print(\"Extracting enhanced data for all book URLs...\")\n",
    "    for index, row in books_df.iterrows():\n",
    "        url = row['URL']\n",
    "        print(f\"Extracting data from: {url}\")\n",
    "        \n",
    "        driver.get(url)\n",
    "        \n",
    "        # Extract Title\n",
    "        try:\n",
    "            title = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"h1[data-testid='bookTitle']\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            title = \"Not Found\"\n",
    "        \n",
    "        # Extract Author\n",
    "        try:\n",
    "            author = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"span.ContributorLink__name\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            author = \"Not Found\"\n",
    "        \n",
    "        # Extract Average Rating\n",
    "        try:\n",
    "            avg_rating = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"div.RatingStatistics__rating\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            avg_rating = \"Not Found\"\n",
    "        \n",
    "        # Extract Publication Date\n",
    "        try:\n",
    "            pub_date = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"p[data-testid='publicationInfo']\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            pub_date = \"Not Found\"\n",
    "        try:\n",
    "            genre = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"a.Button--tag-inline\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            genre = \"Not Found\"\n",
    "        # Extract Genre\n",
    "        try:\n",
    "            genre = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"a.Button--tag-inline\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "    genre = \"Not Found\"\n",
    "\n",
    "        # Extract Number of Ratings\n",
    "        try:\n",
    "            num_ratings = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"div.RatingStatistics__meta > span\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            num_ratings = \"Not Found\"\n",
    "        \n",
    "        # Extract Number of Pages\n",
    "        try:\n",
    "            pages = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"p[data-testid='pagesFormat']\"))\n",
    "            ).text\n",
    "        except TimeoutException:\n",
    "            pages = \"Not Found\"\n",
    "\n",
    "        # Store the Extracted Data\n",
    "        extracted_data.append({\n",
    "            \"URL\": url,\n",
    "            \"Title\": title,\n",
    "            \"Author\": author,\n",
    "            \"Average Rating\": avg_rating,\n",
    "            \"Publication Date\": pub_date,\n",
    "            \"Genre\": genre,\n",
    "            \"Number of Ratings\": num_ratings,\n",
    "            \"Pages\": pages\n",
    "        })\n",
    "\n",
    "        print(f\"Extracted: {title}, {author}, {avg_rating}, {pub_date}, {genre}, {num_ratings}, {pages}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "# Save the Data to a CSV File\n",
    "output_df = pd.DataFrame(extracted_data)\n",
    "output_df.to_csv(output_file, index=False)\n",
    "print(f\"Saved enhanced book data to '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a05d426-d72f-4c48-af3d-4eba515420fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome()  # Ensure chromedriver is set up correctly\n",
    "book_url = \"https://www.goodreads.com/book/show/45047384-the-house-in-the-cerulean-sea\"\n",
    "\n",
    "try:\n",
    "    print(\"Loading book page...\")\n",
    "    driver.get(book_url)\n",
    "    time.sleep(3)  # Allow time for the page to load fully\n",
    "\n",
    "    # Extract the first genre\n",
    "    try:\n",
    "        print(\"Extracting the first genre...\")\n",
    "        first_genre = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"a[href*='/genres/']\"))\n",
    "        ).text\n",
    "        print(f\"First Genre: {first_genre}\")\n",
    "    except TimeoutException:\n",
    "        print(\"Genre not found within the specified timeout.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    driver.quit()\n",
    "    print(\"WebDriver closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84777a26-0d83-43cb-af1d-2cd1b25b9b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import inspect\n",
    "\n",
    "def get_notebook_path():\n",
    "    frame = inspect.currentframe()\n",
    "    try:\n",
    "        # Get the frame where this function is called\n",
    "        frame_info = inspect.getframeinfo(frame)\n",
    "        # Get the absolute path to the current working directory\n",
    "        abs_dir = os.path.abspath('.')\n",
    "        # Combine it with the notebook's filename\n",
    "        notebook_path = os.path.join(abs_dir, frame_info.filename)\n",
    "        return notebook_path\n",
    "    finally:\n",
    "        del frame\n",
    "\n",
    "print(get_notebook_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f7373-d4d9-487b-a150-4c207a090358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
